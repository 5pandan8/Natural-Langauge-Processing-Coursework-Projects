{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Project 4</h1></center>\n",
    "<br>\n",
    "<center><font size=\"5\">Name - Spandan Patil</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from torch.optim.lr_scheduler import StepLR,OneCycleLR\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the dataset\n",
    "def read_Dataset(file_path):\n",
    "    # List of store all the sentences and the labels list.\n",
    "    sents, lbls = [], []\n",
    "    # Variable to store the sentece and the labels for each token in the sentence.\n",
    "    sent, lbl = [], []\n",
    "    # Here we open our dataset file.\n",
    "    with open(file_path, 'r', encoding='utf-8') as c:\n",
    "        # We are reading line by line\n",
    "        for w_dtls in c:\n",
    "            # Here we are removing all the leading and trailing white spaces\n",
    "            w_dtls = w_dtls.strip()\n",
    "            # If the line is not blank\n",
    "            if w_dtls:\n",
    "                # We are spliting the the line\n",
    "                w_dtls_lst = w_dtls.split()\n",
    "                if len(w_dtls_lst) == 3:\n",
    "                    # We are getting the index, word and its tag\n",
    "                    _, w, tag = w_dtls_lst\n",
    "                    sent.append(w)\n",
    "                    lbl.append(tag)\n",
    "                elif len(w_dtls_lst) == 2:\n",
    "                    # We are getting the index and word\n",
    "                    _, w = w_dtls_lst\n",
    "                    sent.append(w)\n",
    "            else:\n",
    "                # If its end of the sentences add it to sentences list.\n",
    "                if sent:\n",
    "                    sents.append(sent)\n",
    "                    lbls.append(lbl)\n",
    "                    sent, lbl = [], []\n",
    "        # For adding the last sentence.\n",
    "        if sent:\n",
    "            sents.append(sent)\n",
    "            lbls.append(lbl)\n",
    "    if file_path == \"./data/test\":\n",
    "        return {\"sentences\": sents}\n",
    "    else:\n",
    "        return {\"sentences\": sents, \"labels\": lbls}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are loading our train, dev and test data.\n",
    "train_data = read_Dataset(\"./data/train\")\n",
    "dev_data = read_Dataset(\"./data/dev\")\n",
    "test_data = read_Dataset(\"./data/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is our BiLSTM model for performing the Name Entity Recognition task.\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, v_size, t_size, embedding_dim=100, hidden_dim=256, linear_dim=128, lstm_layers=1, dropout=0.33):\n",
    "        super(BiLSTM, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(v_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        ).to(device)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, linear_dim).to(device)\n",
    "        self.elu = nn.ELU(alpha=0.01)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(linear_dim, t_size).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        fc_out = self.fc(lstm_out)\n",
    "        elu_out = self.elu(fc_out)\n",
    "        drop_out = self.dropout(elu_out)\n",
    "        scores = self.classifier(drop_out)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the custom dataset to load our datasets.\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, sents, lbls, word2idx, tag2idx):\n",
    "        # Here we are storing the sentences and there labels\n",
    "        self.sents = [[word2idx.get(word, 1) for word in sent] for sent in sents]\n",
    "        self.lbls = [[tag2idx[tag] for tag in label] for label in lbls]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sents)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sents[idx]), torch.tensor(self.lbls[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the custom dataset to load our test datasets.\n",
    "class NERDataset_TEST(Dataset):\n",
    "    def __init__(self, sents, word2idx):\n",
    "        # Here we are storing the sentences\n",
    "        self.sents = [[word2idx.get(word, 1) for word in sent] for sent in sents]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sents)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sents[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to evaluate our Model and writing the prediction to output file.\n",
    "def evaluate(model, dataloader, data, word2idx, tag2idx, batch_size, output_file):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    # The idx to tag dictionary\n",
    "    idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "    # The idx to word dictionary\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    # List to store the true labels\n",
    "    true_lbls = []\n",
    "    # List to store the predictions\n",
    "    preds_lst = []\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        with torch.no_grad():\n",
    "            # Here we are evaluating the datapoints in batches.\n",
    "            for batch_idx, (sents, lbls) in enumerate(dataloader):\n",
    "                sents = sents.to(device)\n",
    "                output = model(sents)\n",
    "                preds = torch.argmax(output, dim=-1)\n",
    "                \n",
    "                # Here we are writing our predictions to the output file.\n",
    "                for sent_idx, (sent, lbl, pred) in enumerate(zip(sents, lbls, preds)):\n",
    "                    for w_idx, (w_id, pred_id, _) in enumerate(zip(sent, pred, lbl)):\n",
    "                        w = idx2word.get(w_id.item(), \"<UNK>\")\n",
    "                        pred_tag = idx2tag[pred_id.item()]\n",
    "                        # This is for skipping the padding.\n",
    "                        if w != \"<PAD>\" and w != \"<S>\" and w != \"</S>\":\n",
    "                            og_w = data[\"sentences\"][batch_idx * batch_size + sent_idx][w_idx-1]\n",
    "                            f.write(f\"{w_idx} {og_w} {pred_tag}\\n\")\n",
    "                    f.write(\"\\n\")\n",
    "                \n",
    "                # Collect the true labels and predictions\n",
    "                for true, pred in zip(lbl, pred):\n",
    "                    # This is for skipping the padding.\n",
    "                    if true.item() != -1:\n",
    "                        true_lbls.append(true.item())\n",
    "                        preds_lst.append(pred.item())\n",
    "    \n",
    "    # Here we are calculating Precision, Recall, F1 Score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_lbls, preds_lst, average='macro', zero_division=0)\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Here we are calculate Accuracy\n",
    "    correct = (torch.tensor(preds_lst) == torch.tensor(true_lbls)).sum().item()\n",
    "    total = len(true_lbls)\n",
    "    print(total)\n",
    "    print(f\"Evaluation Accuracy: {correct / total:.4f}\")\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to evaluate our Model and writing the prediction to output file.\n",
    "def evaluate_test(model, dataloader, data, word2idx, tag2idx, batch_size, output_file):\n",
    "    model.eval()\n",
    "    # The idx to tag dictionary\n",
    "    idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "    # The idx to word dictionary\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    # List to store the true labels\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        with torch.no_grad():\n",
    "            # Here we are evaluating the datapoints in batches.\n",
    "            for batch_idx, sents in enumerate(dataloader):\n",
    "                sents = sents.to(device)\n",
    "                output = model(sents)\n",
    "                preds = torch.argmax(output, dim=-1)\n",
    "                \n",
    "                # Here we are writing our predictions to the output file.\n",
    "                for sent_idx, (sent, pred) in enumerate(zip(sents, preds)):\n",
    "                    for w_idx, (w_id, pred_id) in enumerate(zip(sent, pred)):\n",
    "                        w = idx2word.get(w_id.item(), \"<UNK>\")\n",
    "                        pred_tag = idx2tag[pred_id.item()]\n",
    "                        # This is for skipping the padding.\n",
    "                        if w != \"<PAD>\" and w != \"<S>\" and w != \"</S>\":\n",
    "                            og_w = data[\"sentences\"][batch_idx * batch_size + sent_idx][w_idx-1]\n",
    "                            f.write(f\"{w_idx} {og_w} {pred_tag}\\n\")\n",
    "                    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the function to train our model\n",
    "def train_model(model, train_loader, dev_loader, data, optimizer, criterion, word2idx, tag2idx, batch_size, output_file=\"dev1.out\", epochs=10, accum_steps=1):\n",
    "    model.train()\n",
    "    # This is the learning rate scheduler here we are reducing the learning by 0.5 factor if we dont see improvement in validation f1-score for 4 epoches.\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=4, verbose=True)\n",
    "    model.to(device)\n",
    "    # Variable to store the best f1\n",
    "    best_f1 = float(\"-inf\")\n",
    "    best_model = None\n",
    "    # Paitences counter.\n",
    "    counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # This is to give details regarding each epoches\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        \n",
    "        # Here we are training our model in batches.\n",
    "        for step, (sents, lbls) in enumerate(progress_bar):\n",
    "            sents, lbls = sents.to(device), lbls.to(device)\n",
    "            out = model(sents)\n",
    "            \n",
    "            loss = criterion(out.view(-1, out.shape[-1]), lbls.view(-1)) / accum_steps\n",
    "            loss.backward()\n",
    "\n",
    "            # Here we are doing Gradient accumulation (if accum_steps > 1)\n",
    "            if (step + 1) % accum_steps == 0 or (step + 1) == len(train_loader):\n",
    "                # This is to preventing the exploding gradients problem.\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0) \n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # Here we are calculating the total loss for this epoch.\n",
    "            total_loss += loss.item() * accum_steps\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Calculating the avg loss for the epoch\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Avg Loss: {avg_loss:.4f}, LR: {scheduler.get_last_lr()[0]}\")\n",
    "        \n",
    "        # Here we are running the validation step on our model for the current epoch\n",
    "        f1 = evaluate(model, dev_loader, data, word2idx, tag2idx, batch_size, output_file)\n",
    "        # Updating the learning rate based on the F1 score.\n",
    "        scheduler.step(f1)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            torch.save(model, \"blstm1.pt\")\n",
    "            best_model = model\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        if counter >= 10:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "        \n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, word_to_index, tag_to_index, pad_token='<PAD>', init_token='<S>', eos_token='</S>'):\n",
    "    sentences, labels = zip(*batch)\n",
    "    \n",
    "    # Add <s> and </s> tokens for both sentences and labels\n",
    "    sentences_padded = [([word_to_index[init_token]] + list(sentence) + [word_to_index[eos_token]]) for sentence in sentences]\n",
    "    labels_padded = [([tag_to_index[pad_token]] + list(label) + [tag_to_index[pad_token]]) for label in labels]\n",
    "    \n",
    "    # Pad the sequences\n",
    "    max_len = max(len(sentence) for sentence in sentences_padded)\n",
    "    sentences_padded = [sentence + [word_to_index[pad_token]] * (max_len - len(sentence)) for sentence in sentences_padded]\n",
    "    labels_padded = [label + [tag_to_index[pad_token]] * (max_len - len(label)) for label in labels_padded]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    sentences_padded = torch.tensor(sentences_padded, dtype=torch.long).to(device)\n",
    "    labels_padded = torch.tensor(labels_padded, dtype=torch.long).to(device)\n",
    "\n",
    "    return sentences_padded, labels_padded\n",
    "\n",
    "def collate_fn_test(batch, word_to_index, pad_token='<PAD>', init_token='<S>', eos_token='</S>'):\n",
    "    \n",
    "    \n",
    "    # Add <s> and </s> tokens for both sentences and labels\n",
    "    sentences_padded = [([word_to_index[init_token]] + list(sentence) + [word_to_index[eos_token]]) for sentence in batch]\n",
    "    \n",
    "    # Pad the sequences\n",
    "    max_len = max(len(sentence) for sentence in sentences_padded)\n",
    "    sentences_padded = [sentence + [word_to_index[pad_token]] * (max_len - len(sentence)) for sentence in sentences_padded]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    sentences_padded = torch.tensor(sentences_padded, dtype=torch.long).to(device)\n",
    "\n",
    "    return sentences_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Hyperparameters for the model\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "linear_dim = 128\n",
    "dropout = 0.33\n",
    "batch_size = 16\n",
    "learning_rate = 0.25\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "# Here we are building our Vocabulary from Training Data\n",
    "word2idx = {word: idx for idx, word in enumerate(set(word for sent in train_data['sentences'] for word in sent), start=4)}\n",
    "# Here we are adding the indices for padding and unknown words.\n",
    "word2idx[\"<PAD>\"] = 0\n",
    "word2idx[\"<UNK>\"] = 1\n",
    "word2idx[\"<S>\"] = 2\n",
    "word2idx[\"</S>\"] = 3\n",
    "# Here we are creating our numeric label mapping.\n",
    "tag2idx = {tag: idx for idx, tag in enumerate(set(tag for label in train_data['labels'] for tag in label))}\n",
    "tag2idx[\"<PAD>\"] = -1\n",
    "vocab_size = len(word2idx)\n",
    "tagset_size = len(tag2idx)-1\n",
    "\n",
    "\n",
    "# Here we are creating our BLSTM model for training.\n",
    "model = BiLSTM(vocab_size, tagset_size, embedding_dim, hidden_dim, linear_dim, dropout=dropout).to(device)\n",
    "\n",
    "# Here we are creating the opitmizer SGD.\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.00005, nesterov=True)\n",
    "# Here we are defining the loss function.\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1).to(device)\n",
    "\n",
    "# Here we are loading our datasets.\n",
    "dataset_train = NERDataset(train_data['sentences'], train_data['labels'], word2idx, tag2idx)\n",
    "dataset_dev = NERDataset(dev_data['sentences'], dev_data['labels'], word2idx, tag2idx)\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=lambda batch: collate_fn(batch, word2idx, tag2idx))\n",
    "dev_loader = DataLoader(dataset_dev, batch_size=batch_size, collate_fn=lambda batch: collate_fn(batch, word2idx, tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Avg Loss: 0.4828, LR: 0.25\n",
      "Precision: 0.7947, Recall: 0.5033, F1 Score: 0.5939\n",
      "3324\n",
      "Evaluation Accuracy: 0.8995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Avg Loss: 0.2386, LR: 0.25\n",
      "Precision: 0.8754, Recall: 0.5731, F1 Score: 0.6782\n",
      "3324\n",
      "Evaluation Accuracy: 0.9161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Avg Loss: 0.1560, LR: 0.25\n",
      "Precision: 0.8413, Recall: 0.6377, F1 Score: 0.7163\n",
      "3324\n",
      "Evaluation Accuracy: 0.9269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Avg Loss: 0.1111, LR: 0.25\n",
      "Precision: 0.8542, Recall: 0.6664, F1 Score: 0.7447\n",
      "3324\n",
      "Evaluation Accuracy: 0.9293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Avg Loss: 0.0847, LR: 0.25\n",
      "Precision: 0.9028, Recall: 0.6762, F1 Score: 0.7636\n",
      "3324\n",
      "Evaluation Accuracy: 0.9335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Avg Loss: 0.0651, LR: 0.25\n",
      "Precision: 0.8874, Recall: 0.7191, F1 Score: 0.7905\n",
      "3324\n",
      "Evaluation Accuracy: 0.9377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Avg Loss: 0.0321, LR: 0.125\n",
      "Precision: 0.8971, Recall: 0.7036, F1 Score: 0.7825\n",
      "3324\n",
      "Evaluation Accuracy: 0.9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Avg Loss: 0.0216, LR: 0.125\n",
      "Precision: 0.8820, Recall: 0.7444, F1 Score: 0.7992\n",
      "3324\n",
      "Evaluation Accuracy: 0.9419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Avg Loss: 0.0192, LR: 0.125\n",
      "Precision: 0.8958, Recall: 0.7060, F1 Score: 0.7831\n",
      "3324\n",
      "Evaluation Accuracy: 0.9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Avg Loss: 0.0209, LR: 0.125\n",
      "Precision: 0.9025, Recall: 0.6827, F1 Score: 0.7706\n",
      "3324\n",
      "Evaluation Accuracy: 0.9335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Avg Loss: 0.0215, LR: 0.125\n",
      "Precision: 0.8253, Recall: 0.7250, F1 Score: 0.7694\n",
      "3324\n",
      "Evaluation Accuracy: 0.9380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Avg Loss: 0.0120, LR: 0.0625\n",
      "Precision: 0.8941, Recall: 0.7368, F1 Score: 0.8012\n",
      "3324\n",
      "Evaluation Accuracy: 0.9440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Avg Loss: 0.0088, LR: 0.0625\n",
      "Precision: 0.9021, Recall: 0.7229, F1 Score: 0.7960\n",
      "3324\n",
      "Evaluation Accuracy: 0.9422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Avg Loss: 0.0086, LR: 0.0625\n",
      "Precision: 0.9048, Recall: 0.7107, F1 Score: 0.7890\n",
      "3324\n",
      "Evaluation Accuracy: 0.9416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Avg Loss: 0.0084, LR: 0.0625\n",
      "Precision: 0.9197, Recall: 0.7358, F1 Score: 0.8132\n",
      "3324\n",
      "Evaluation Accuracy: 0.9452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Avg Loss: 0.0088, LR: 0.0625\n",
      "Precision: 0.9244, Recall: 0.7155, F1 Score: 0.7992\n",
      "3324\n",
      "Evaluation Accuracy: 0.9428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Avg Loss: 0.0068, LR: 0.03125\n",
      "Precision: 0.9178, Recall: 0.7287, F1 Score: 0.8046\n",
      "3324\n",
      "Evaluation Accuracy: 0.9437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Avg Loss: 0.0060, LR: 0.03125\n",
      "Precision: 0.8967, Recall: 0.7323, F1 Score: 0.8015\n",
      "3324\n",
      "Evaluation Accuracy: 0.9440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Avg Loss: 0.0063, LR: 0.03125\n",
      "Precision: 0.9160, Recall: 0.7289, F1 Score: 0.8055\n",
      "3324\n",
      "Evaluation Accuracy: 0.9455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Avg Loss: 0.0068, LR: 0.03125\n",
      "Precision: 0.9015, Recall: 0.7297, F1 Score: 0.8005\n",
      "3324\n",
      "Evaluation Accuracy: 0.9437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Avg Loss: 0.0069, LR: 0.03125\n",
      "Precision: 0.9185, Recall: 0.7187, F1 Score: 0.8002\n",
      "3324\n",
      "Evaluation Accuracy: 0.9431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Avg Loss: 0.0059, LR: 0.015625\n",
      "Precision: 0.9190, Recall: 0.7251, F1 Score: 0.8033\n",
      "3324\n",
      "Evaluation Accuracy: 0.9437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Avg Loss: 0.0058, LR: 0.015625\n",
      "Precision: 0.9126, Recall: 0.7313, F1 Score: 0.8066\n",
      "3324\n",
      "Evaluation Accuracy: 0.9443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Avg Loss: 0.0059, LR: 0.015625\n",
      "Precision: 0.9038, Recall: 0.7346, F1 Score: 0.8051\n",
      "3324\n",
      "Evaluation Accuracy: 0.9449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Avg Loss: 0.0060, LR: 0.015625\n",
      "Precision: 0.9293, Recall: 0.7238, F1 Score: 0.8059\n",
      "3324\n",
      "Evaluation Accuracy: 0.9443\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating the Model\n",
    "best_model = train_model(model, train_loader, dev_loader, dev_data, optimizer, criterion, word2idx, tag2idx, batch_size, \"./dev1.out\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9197, Recall: 0.7358, F1 Score: 0.8132\n",
      "3324\n",
      "Evaluation Accuracy: 0.9452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8131798357408604"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the state dictionary\n",
    "best_model = torch.load('./blstm1.pt')\n",
    "best_model.to(device)\n",
    "evaluate(best_model, dev_loader, dev_data, word2idx, tag2idx, batch_size, \"./dev1.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51578 tokens with 5942 phrases; found: 5029 phrases; correct: 4153.\n",
      "accuracy:  94.93%; precision:  82.58%; recall:  69.89%; FB1:  75.71\n",
      "              LOC: precision:  92.38%; recall:  77.19%; FB1:  84.10  1535\n",
      "             MISC: precision:  84.25%; recall:  76.03%; FB1:  79.93  832\n",
      "              ORG: precision:  76.99%; recall:  64.13%; FB1:  69.98  1117\n",
      "              PER: precision:  75.99%; recall:  63.74%; FB1:  69.32  1545\n"
     ]
    }
   ],
   "source": [
    "# Evaluating METRICS with eval.py\n",
    "!python eval.py -p dev1.out -g data/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state dictionary\n",
    "best_model = torch.load('./blstm1.pt')\n",
    "best_model.to(device)\n",
    "dataset_test = NERDataset_TEST(test_data['sentences'], word2idx)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, collate_fn=lambda batch: collate_fn_test(batch, word2idx))\n",
    "evaluate_test(best_model, test_loader, test_data, word2idx, tag2idx, batch_size, \"./test1.out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is our BiLSTM model for performing the Name Entity Recognition task.\n",
    "class BiLSTM_Glove(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_matrix=None, embedding_dim=100, hidden_dim=256, linear_dim=128, lstm_layers=1, dropout=0.33, capitalization_dim=6):\n",
    "        super(BiLSTM_Glove, self).__init__()\n",
    "        \n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                torch.from_numpy(embedding_matrix).float(),\n",
    "                padding_idx=0,\n",
    "                freeze=False\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # Here we are adding a new embedding layer for capitalization feature\n",
    "        self.capitalization_embedding = nn.Embedding(capitalization_dim, embedding_dim, padding_idx=0)  \n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim * 2,  # multiple by 2 is to account for both word and capitalization embeddings\n",
    "            hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout  \n",
    "        ).to(device)\n",
    "\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, linear_dim).to(device)\n",
    "        self.elu = nn.ELU(alpha=0.01)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(linear_dim, tagset_size).to(device)\n",
    "    \n",
    "    def forward(self, x, capitalization_features):\n",
    "        embedded = self.embedding(x)\n",
    "        # Here we are getting capitalization embeddings\n",
    "        capitalization_embeds = self.capitalization_embedding(capitalization_features)  \n",
    "        # Here we are concatenating the word and capitalization embeddings\n",
    "        combined_embeds = torch.cat((embedded, capitalization_embeds), dim=-1)  \n",
    "        lstm_out, _ = self.lstm(combined_embeds)\n",
    "        fc_out = self.fc(lstm_out)\n",
    "        elu_out = self.elu(fc_out)\n",
    "        drop_out = self.dropout(elu_out)\n",
    "        scores = self.classifier(drop_out)\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this function we are determining the capitalization feature label for each word.\n",
    "def get_capitalization_feature(word):\n",
    "    # Check if the word is fully uppercase\n",
    "    if word.isupper():\n",
    "        return 'allCaps'\n",
    "    # Check if the word starts with an uppercase letter and the rest are lowercase\n",
    "    elif word[0].isupper() and word[1:].islower():\n",
    "        return 'upperInitial'\n",
    "    # Check if the word is entirely lowercase\n",
    "    elif word.islower():\n",
    "        return 'lowercase'\n",
    "    # Check if the word has mixed capitalization\n",
    "    elif any(c.isupper() for c in word[1:]) and any(c.islower() for c in word[1:]):\n",
    "        return 'mixedCaps'\n",
    "    else:\n",
    "        return 'noinfo'\n",
    "\n",
    "# Here we are mapping each of the capitalization feature label to numeric label.\n",
    "def capitalization_to_index(capitalization):\n",
    "    lookup = {\n",
    "        '<PAD>' : 0,\n",
    "        'allCaps': 1,\n",
    "        'upperInitial': 2,\n",
    "        'lowercase': 3,\n",
    "        'mixedCaps': 4,\n",
    "        'noinfo': 5\n",
    "    }\n",
    "    return lookup.get(capitalization, 4)  # default to 'noinfo' if invalid\n",
    "\n",
    "# In this function we are checking for capitalization\n",
    "def adjust_case(word):\n",
    "    if word.islower():\n",
    "        return word.lower()\n",
    "    elif word.isupper():\n",
    "        return word.upper()\n",
    "    elif word.istitle():\n",
    "        return word.title()\n",
    "    else:\n",
    "        return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the custom dataset to load our datasets with capitalization.\n",
    "class NERDataset_Glove(Dataset):\n",
    "    def __init__(self, sentences, labels, word2idx, tag2idx):\n",
    "        self.sentences = [[word2idx.get(word, 1) for word in sent] for sent in sentences]\n",
    "        self.capitalization_features = [[capitalization_to_index(get_capitalization_feature(word)) for word in sent] for sent in sentences]\n",
    "        self.labels = [[tag2idx[tag] for tag in label] for label in labels]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sentences[idx]), torch.tensor(self.capitalization_features[idx]), torch.tensor(self.labels[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the custom dataset to load our datasets with capitalization.\n",
    "class NERDataset_Glove_test(Dataset):\n",
    "    def __init__(self, sentences, word2idx):\n",
    "        self.sentences = [[word2idx.get(word, 1) for word in sent] for sent in sentences]\n",
    "        self.capitalization_features = [[capitalization_to_index(get_capitalization_feature(word)) for word in sent] for sent in sentences]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sentences[idx]), torch.tensor(self.capitalization_features[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to evaluate our Model and writing the prediction to output file.\n",
    "def evaluate_glove(model, dataloader, data, word2idx, tag2idx, batch_size, output_file):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    # The idx to tag dictionary\n",
    "    idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "    # The idx to word dictionary\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    # List to store the true labels\n",
    "    true_lbls = []\n",
    "    # List to store the predictions\n",
    "    preds_lst = []\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        with torch.no_grad():\n",
    "            # Here we are evaluating the datapoints in batches.\n",
    "            for batch_idx, (sents, cps, lbls) in enumerate(dataloader):\n",
    "                sents = sents.to(device)\n",
    "                cps = cps.to(device)\n",
    "                output = model(sents, cps)\n",
    "                preds = torch.argmax(output, dim=-1)\n",
    "                # Here we are writing our predictions to the output file.\n",
    "                for sent_idx, (sent, lbl, pred) in enumerate(zip(sents, lbls, preds)):\n",
    "                    for w_idx, (w_id, pred_id, _) in enumerate(zip(sent, pred, lbl)):\n",
    "                        w = idx2word.get(w_id.item(), \"<UNK>\")\n",
    "                        pred_tag = idx2tag[pred_id.item()]\n",
    "                        # This is for skipping the padding.\n",
    "                        if w != \"<PAD>\" and w != \"<S>\" and w != \"</S>\":\n",
    "                            og_w = data[\"sentences\"][batch_idx * batch_size + sent_idx][w_idx-1]\n",
    "                            f.write(f\"{w_idx} {og_w} {pred_tag}\\n\")\n",
    "                    f.write(\"\\n\")\n",
    "                \n",
    "                # Collect the true labels and predictions\n",
    "                for true, pred in zip(lbl, pred):\n",
    "                    # This is for skipping the padding.\n",
    "                    if true.item() != -1:\n",
    "                        true_lbls.append(true.item())\n",
    "                        preds_lst.append(pred.item())\n",
    "    \n",
    "    # Here we are calculating Precision, Recall, F1 Score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_lbls, preds_lst, average='macro', zero_division=0)\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Here we are calculate Accuracy\n",
    "    correct = (torch.tensor(preds_lst) == torch.tensor(true_lbls)).sum().item()\n",
    "    total = len(true_lbls)\n",
    "    print(f\"Evaluation Accuracy: {correct / total:.4f}\")\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to evaluate our Model and writing the prediction to output file.\n",
    "def evaluate_glove_test(model, dataloader, data, word2idx, tag2idx, batch_size, output_file):\n",
    "    model.eval()\n",
    "    # The idx to tag dictionary\n",
    "    idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "    # The idx to word dictionary\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    # List to store the true labels\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        with torch.no_grad():\n",
    "            # Here we are evaluating the datapoints in batches.\n",
    "            for batch_idx, (sents, cps) in enumerate(dataloader):\n",
    "                sents = sents.to(device)\n",
    "                cps = cps.to(device)\n",
    "                output = model(sents, cps)\n",
    "                preds = torch.argmax(output, dim=-1)\n",
    "                \n",
    "                # Here we are writing our predictions to the output file.\n",
    "                for sent_idx, (sent, pred) in enumerate(zip(sents, preds)):\n",
    "                    for w_idx, (w_id, pred_id) in enumerate(zip(sent, pred)):\n",
    "                        w = idx2word.get(w_id.item(), \"<UNK>\")\n",
    "                        pred_tag = idx2tag[pred_id.item()]\n",
    "                        # This is for skipping the padding.\n",
    "                        if w != \"<PAD>\" and w != \"<S>\" and w != \"</S>\":\n",
    "                            og_w = data[\"sentences\"][batch_idx * batch_size + sent_idx][w_idx-1]\n",
    "                            f.write(f\"{w_idx} {og_w} {pred_tag}\\n\")\n",
    "                    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the function to train our model\n",
    "def train_model_glove(model, train_loader, dev_loader, data, optimizer, criterion, word2idx, tag2idx, batch_size, output_file=\"./dev2.out\", epochs=10, accum_steps=1):\n",
    "    model.train()\n",
    "    # This is the learning rate scheduler here we are reducing the learning by 0.5 factor if we dont see improvement in validation f1-score for paitence number of epoches.\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=4)\n",
    "    model.to(device)\n",
    "    # Variable to store the best f1\n",
    "    best_f1 = float(\"-inf\")\n",
    "    # Variable to store best model\n",
    "    best_model = None\n",
    "    # Paitences counter.\n",
    "    counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # This is to give details regarding each epoches\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "\n",
    "        # Here we are training our model in batches.\n",
    "        for step, (sentences, cps, labels) in enumerate(progress_bar):\n",
    "            sentences, cps, labels = sentences.to(device), cps.to(device), labels.to(device)\n",
    "            output = model(sentences, cps)\n",
    "\n",
    "            loss = criterion(output.view(-1, output.shape[-1]), labels.view(-1)) / accum_steps\n",
    "            loss.backward()\n",
    "\n",
    "            # Here we are doing Gradient accumulation (if accum_steps > 1)\n",
    "            if (step + 1) % accum_steps == 0 or (step + 1) == len(train_loader):\n",
    "                # This is to preventing the exploding gradients problem.\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item() * accum_steps\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Calculating the avg loss for the epoch\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Avg Loss: {avg_loss:.4f}, LR: {scheduler.get_last_lr()[0]}\")\n",
    "        # Here we are running the validation step on our model for the current epoch\n",
    "        f1 = evaluate_glove(model, dev_loader, data, word2idx, tag2idx, batch_size, output_file)  \n",
    "        # Updating the learning rate based on the F1 score.\n",
    "        scheduler.step(f1)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            torch.save(model, \"blstm2.pt\")\n",
    "            best_model = model\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        if counter >= 10:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Function is used to create the embedding matrix from the glove embedding.\n",
    "def create_embedding_matrix(vocab, embeddings, embedding_dim=100):\n",
    "    # Here we are intializing a zero matrix of the correct dimensions.\n",
    "    embedding_matrix = np.zeros((len(vocab), embedding_dim))\n",
    "    # Here we are updating the initalized matrix with embedding vectors.\n",
    "    for word, idx in vocab.items():\n",
    "        if word in embeddings:\n",
    "            embedding_matrix[idx] = embeddings[word]\n",
    "        elif word.lower() in embeddings:\n",
    "            embedding_matrix[idx] = embeddings[word.lower()]\n",
    "        elif word.upper() in embeddings:\n",
    "            embedding_matrix[idx] = embeddings[word.upper()] \n",
    "        else:\n",
    "            # Initialize randomly with small values for OOV words\n",
    "            embedding_matrix[idx] = np.random.uniform(-0.25, 0.25, embedding_dim)\n",
    "    \n",
    "    return embedding_matrix\n",
    "\n",
    "# This Function is to to load GloVe embeddings\n",
    "def load_glove_embeddings(glove_file_path):\n",
    "    embeddings = {}\n",
    "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_glove(batch, word_to_index, tag_to_index, pad_token='<PAD>', init_token='<S>', eos_token='</S>'):\n",
    "    sentences, cps, labels = zip(*batch)\n",
    "    \n",
    "    # Add <s> and </s> tokens for both sentences and labels\n",
    "    sentences_padded = [([word_to_index[init_token]] + list(sentence) + [word_to_index[eos_token]]) for sentence in sentences]\n",
    "    labels_padded = [([tag_to_index[pad_token]] + list(label) + [tag_to_index[pad_token]]) for label in labels]\n",
    "    cp_padded = [([capitalization_to_index(pad_token)] + list(cp) + [capitalization_to_index(pad_token)]) for cp in cps]\n",
    "    # Pad the sequences\n",
    "    max_len = max(len(sentence) for sentence in sentences_padded)\n",
    "    sentences_padded = [sentence + [word_to_index[pad_token]] * (max_len - len(sentence)) for sentence in sentences_padded]\n",
    "    labels_padded = [label + [tag_to_index[pad_token]] * (max_len - len(label)) for label in labels_padded]\n",
    "    cp_padded = [cp + [capitalization_to_index(pad_token)] * (max_len - len(cp)) for cp in cp_padded]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    sentences_padded = torch.tensor(sentences_padded, dtype=torch.long).to(device)\n",
    "    labels_padded = torch.tensor(labels_padded, dtype=torch.long).to(device)\n",
    "    cp_padded = torch.tensor(cp_padded, dtype=torch.long).to(device)\n",
    "\n",
    "    return sentences_padded, cp_padded, labels_padded \n",
    "\n",
    "def collate_fn_glove_test(batch, word_to_index, pad_token='<PAD>', init_token='<S>', eos_token='</S>'):\n",
    "    sentences, cps = zip(*batch)\n",
    "    \n",
    "    # Add <s> and </s> tokens for both sentences and labels\n",
    "    sentences_padded = [([word_to_index[init_token]] + list(sentence) + [word_to_index[eos_token]]) for sentence in sentences]\n",
    "    cp_padded = [([capitalization_to_index(pad_token)] + list(cp) + [capitalization_to_index(pad_token)]) for cp in cps]\n",
    "    \n",
    "    # Pad the sequences\n",
    "    max_len = max(len(sentence) for sentence in sentences_padded)\n",
    "    sentences_padded = [sentence + [word_to_index[pad_token]] * (max_len - len(sentence)) for sentence in sentences_padded]\n",
    "    cp_padded = [cp + [capitalization_to_index(pad_token)] * (max_len - len(cp)) for cp in cp_padded]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    sentences_padded = torch.tensor(sentences_padded, dtype=torch.long).to(device)\n",
    "    cp_padded = torch.tensor(cp_padded, dtype=torch.long).to(device)\n",
    "\n",
    "    return sentences_padded, cp_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "linear_dim = 128\n",
    "dropout = 0.33\n",
    "batch_size = 16\n",
    "learning_rate = 0.25\n",
    "epochs = 80\n",
    "\n",
    "\n",
    "# Build Vocabulary from Training Data\n",
    "word2idx = {word: idx for idx, word in enumerate(set(word for sent in train_data['sentences'] for word in sent), start=4)}\n",
    "word2idx[\"<PAD>\"] = 0\n",
    "word2idx[\"<UNK>\"] = 1\n",
    "word2idx[\"<S>\"] = 2\n",
    "word2idx[\"</S>\"] = 3\n",
    "tag2idx = {tag: idx for idx, tag in enumerate(set(tag for label in train_data['labels'] for tag in label))}\n",
    "tag2idx[\"<PAD>\"] = -1\n",
    "vocab_size = len(word2idx)\n",
    "tagset_size = len(tag2idx)-1\n",
    "\n",
    "\n",
    "glove_embeddings = load_glove_embeddings(\"./glove.6B.100d/glove.6B.100d.txt\")\n",
    "\n",
    "# Create the embedding matrix from the trained Word2Vec model\n",
    "embedding_matrix = create_embedding_matrix(word2idx, glove_embeddings, embedding_dim)\n",
    "\n",
    "# Model, Optimizer, and Loss Function\n",
    "model = BiLSTM_Glove(vocab_size, tagset_size, embedding_matrix, embedding_dim, hidden_dim, linear_dim, dropout=dropout).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-5, nesterov=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1).to(device)\n",
    "\n",
    "# Load Data\n",
    "dataset_train = NERDataset_Glove(train_data['sentences'], train_data['labels'], word2idx, tag2idx)\n",
    "dataset_dev = NERDataset_Glove(dev_data['sentences'], dev_data['labels'], word2idx, tag2idx)\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=lambda batch: collate_fn_glove(batch, word2idx, tag2idx))\n",
    "dev_loader = DataLoader(dataset_dev, batch_size=batch_size, collate_fn=lambda batch: collate_fn_glove(batch, word2idx, tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80, Avg Loss: 0.1546, LR: 0.25\n",
      "Precision: 0.7901, Recall: 0.7417, F1 Score: 0.7585\n",
      "Evaluation Accuracy: 0.9510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/80, Avg Loss: 0.0758, LR: 0.25\n",
      "Precision: 0.8355, Recall: 0.7737, F1 Score: 0.7977\n",
      "Evaluation Accuracy: 0.9573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/80, Avg Loss: 0.0556, LR: 0.25\n",
      "Precision: 0.8654, Recall: 0.7898, F1 Score: 0.8188\n",
      "Evaluation Accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/80, Avg Loss: 0.0415, LR: 0.25\n",
      "Precision: 0.8666, Recall: 0.8113, F1 Score: 0.8344\n",
      "Evaluation Accuracy: 0.9618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/80, Avg Loss: 0.0322, LR: 0.25\n",
      "Precision: 0.8655, Recall: 0.8121, F1 Score: 0.8331\n",
      "Evaluation Accuracy: 0.9633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/80, Avg Loss: 0.0259, LR: 0.25\n",
      "Precision: 0.8646, Recall: 0.8471, F1 Score: 0.8514\n",
      "Evaluation Accuracy: 0.9654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/80, Avg Loss: 0.0197, LR: 0.25\n",
      "Precision: 0.8970, Recall: 0.8647, F1 Score: 0.8775\n",
      "Evaluation Accuracy: 0.9702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/80, Avg Loss: 0.0161, LR: 0.25\n",
      "Precision: 0.9188, Recall: 0.8240, F1 Score: 0.8633\n",
      "Evaluation Accuracy: 0.9669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/80, Avg Loss: 0.0120, LR: 0.25\n",
      "Precision: 0.8649, Recall: 0.8248, F1 Score: 0.8335\n",
      "Evaluation Accuracy: 0.9636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/80, Avg Loss: 0.0099, LR: 0.25\n",
      "Precision: 0.8887, Recall: 0.8588, F1 Score: 0.8657\n",
      "Evaluation Accuracy: 0.9693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/80, Avg Loss: 0.0086, LR: 0.25\n",
      "Precision: 0.8930, Recall: 0.8666, F1 Score: 0.8742\n",
      "Evaluation Accuracy: 0.9705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/80, Avg Loss: 0.0061, LR: 0.25\n",
      "Precision: 0.8832, Recall: 0.8372, F1 Score: 0.8549\n",
      "Evaluation Accuracy: 0.9672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/80, Avg Loss: 0.0037, LR: 0.125\n",
      "Precision: 0.9052, Recall: 0.8575, F1 Score: 0.8778\n",
      "Evaluation Accuracy: 0.9705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/80, Avg Loss: 0.0025, LR: 0.125\n",
      "Precision: 0.8948, Recall: 0.8626, F1 Score: 0.8745\n",
      "Evaluation Accuracy: 0.9708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/80, Avg Loss: 0.0021, LR: 0.125\n",
      "Precision: 0.9043, Recall: 0.8515, F1 Score: 0.8714\n",
      "Evaluation Accuracy: 0.9699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/80, Avg Loss: 0.0018, LR: 0.125\n",
      "Precision: 0.8973, Recall: 0.8705, F1 Score: 0.8779\n",
      "Evaluation Accuracy: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/80, Avg Loss: 0.0015, LR: 0.125\n",
      "Precision: 0.9109, Recall: 0.8509, F1 Score: 0.8746\n",
      "Evaluation Accuracy: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/80, Avg Loss: 0.0016, LR: 0.125\n",
      "Precision: 0.8898, Recall: 0.8540, F1 Score: 0.8672\n",
      "Evaluation Accuracy: 0.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/80, Avg Loss: 0.0016, LR: 0.125\n",
      "Precision: 0.8958, Recall: 0.8652, F1 Score: 0.8769\n",
      "Evaluation Accuracy: 0.9708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/80, Avg Loss: 0.0014, LR: 0.125\n",
      "Precision: 0.8980, Recall: 0.8661, F1 Score: 0.8785\n",
      "Evaluation Accuracy: 0.9708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/80, Avg Loss: 0.0013, LR: 0.125\n",
      "Precision: 0.9002, Recall: 0.8603, F1 Score: 0.8725\n",
      "Evaluation Accuracy: 0.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/80, Avg Loss: 0.0012, LR: 0.125\n",
      "Precision: 0.9023, Recall: 0.8514, F1 Score: 0.8720\n",
      "Evaluation Accuracy: 0.9705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/80, Avg Loss: 0.0012, LR: 0.125\n",
      "Precision: 0.8944, Recall: 0.8530, F1 Score: 0.8706\n",
      "Evaluation Accuracy: 0.9699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/80, Avg Loss: 0.0012, LR: 0.125\n",
      "Precision: 0.9018, Recall: 0.8636, F1 Score: 0.8793\n",
      "Evaluation Accuracy: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/80, Avg Loss: 0.0011, LR: 0.125\n",
      "Precision: 0.9026, Recall: 0.8683, F1 Score: 0.8807\n",
      "Evaluation Accuracy: 0.9711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/80, Avg Loss: 0.0011, LR: 0.125\n",
      "Precision: 0.8874, Recall: 0.8646, F1 Score: 0.8715\n",
      "Evaluation Accuracy: 0.9699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/80, Avg Loss: 0.0010, LR: 0.125\n",
      "Precision: 0.9065, Recall: 0.8600, F1 Score: 0.8794\n",
      "Evaluation Accuracy: 0.9717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/80, Avg Loss: 0.0008, LR: 0.125\n",
      "Precision: 0.9070, Recall: 0.8605, F1 Score: 0.8803\n",
      "Evaluation Accuracy: 0.9723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/80, Avg Loss: 0.0012, LR: 0.125\n",
      "Precision: 0.9005, Recall: 0.8617, F1 Score: 0.8779\n",
      "Evaluation Accuracy: 0.9711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/80, Avg Loss: 0.0009, LR: 0.125\n",
      "Precision: 0.9004, Recall: 0.8813, F1 Score: 0.8882\n",
      "Evaluation Accuracy: 0.9732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/80, Avg Loss: 0.0011, LR: 0.125\n",
      "Precision: 0.9034, Recall: 0.8624, F1 Score: 0.8801\n",
      "Evaluation Accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/80, Avg Loss: 0.0012, LR: 0.125\n",
      "Precision: 0.9147, Recall: 0.8634, F1 Score: 0.8823\n",
      "Evaluation Accuracy: 0.9735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/80, Avg Loss: 0.0010, LR: 0.125\n",
      "Precision: 0.9000, Recall: 0.8666, F1 Score: 0.8814\n",
      "Evaluation Accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/80, Avg Loss: 0.0015, LR: 0.125\n",
      "Precision: 0.8912, Recall: 0.8640, F1 Score: 0.8718\n",
      "Evaluation Accuracy: 0.9702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/80, Avg Loss: 0.0011, LR: 0.125\n",
      "Precision: 0.9049, Recall: 0.8762, F1 Score: 0.8867\n",
      "Evaluation Accuracy: 0.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/80, Avg Loss: 0.0007, LR: 0.0625\n",
      "Precision: 0.9063, Recall: 0.8668, F1 Score: 0.8828\n",
      "Evaluation Accuracy: 0.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/80, Avg Loss: 0.0006, LR: 0.0625\n",
      "Precision: 0.8992, Recall: 0.8855, F1 Score: 0.8886\n",
      "Evaluation Accuracy: 0.9747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/80, Avg Loss: 0.0006, LR: 0.0625\n",
      "Precision: 0.8995, Recall: 0.8741, F1 Score: 0.8829\n",
      "Evaluation Accuracy: 0.9723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/80, Avg Loss: 0.0005, LR: 0.0625\n",
      "Precision: 0.9057, Recall: 0.8721, F1 Score: 0.8841\n",
      "Evaluation Accuracy: 0.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/80, Avg Loss: 0.0006, LR: 0.0625\n",
      "Precision: 0.9025, Recall: 0.8750, F1 Score: 0.8857\n",
      "Evaluation Accuracy: 0.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/80, Avg Loss: 0.0005, LR: 0.0625\n",
      "Precision: 0.8962, Recall: 0.8731, F1 Score: 0.8810\n",
      "Evaluation Accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/80, Avg Loss: 0.0005, LR: 0.0625\n",
      "Precision: 0.8976, Recall: 0.8754, F1 Score: 0.8829\n",
      "Evaluation Accuracy: 0.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/80, Avg Loss: 0.0005, LR: 0.03125\n",
      "Precision: 0.9020, Recall: 0.8752, F1 Score: 0.8852\n",
      "Evaluation Accuracy: 0.9726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/80, Avg Loss: 0.0005, LR: 0.03125\n",
      "Precision: 0.9059, Recall: 0.8742, F1 Score: 0.8871\n",
      "Evaluation Accuracy: 0.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/80, Avg Loss: 0.0004, LR: 0.03125\n",
      "Precision: 0.9025, Recall: 0.8746, F1 Score: 0.8854\n",
      "Evaluation Accuracy: 0.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/80, Avg Loss: 0.0005, LR: 0.03125\n",
      "Precision: 0.9093, Recall: 0.8754, F1 Score: 0.8894\n",
      "Evaluation Accuracy: 0.9732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/80, Avg Loss: 0.0005, LR: 0.03125\n",
      "Precision: 0.8996, Recall: 0.8716, F1 Score: 0.8821\n",
      "Evaluation Accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/80, Avg Loss: 0.0004, LR: 0.03125\n",
      "Precision: 0.9005, Recall: 0.8722, F1 Score: 0.8833\n",
      "Evaluation Accuracy: 0.9726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/80, Avg Loss: 0.0004, LR: 0.03125\n",
      "Precision: 0.9046, Recall: 0.8750, F1 Score: 0.8869\n",
      "Evaluation Accuracy: 0.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/80, Avg Loss: 0.0004, LR: 0.03125\n",
      "Precision: 0.9018, Recall: 0.8713, F1 Score: 0.8833\n",
      "Evaluation Accuracy: 0.9723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/80, Avg Loss: 0.0004, LR: 0.03125\n",
      "Precision: 0.8988, Recall: 0.8746, F1 Score: 0.8835\n",
      "Evaluation Accuracy: 0.9726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/80, Avg Loss: 0.0004, LR: 0.015625\n",
      "Precision: 0.8981, Recall: 0.8741, F1 Score: 0.8830\n",
      "Evaluation Accuracy: 0.9723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80, Avg Loss: 0.0004, LR: 0.015625\n",
      "Precision: 0.8986, Recall: 0.8728, F1 Score: 0.8825\n",
      "Evaluation Accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/80, Avg Loss: 0.0004, LR: 0.015625\n",
      "Precision: 0.9006, Recall: 0.8737, F1 Score: 0.8837\n",
      "Evaluation Accuracy: 0.9726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/80, Avg Loss: 0.0004, LR: 0.015625\n",
      "Precision: 0.9024, Recall: 0.8750, F1 Score: 0.8854\n",
      "Evaluation Accuracy: 0.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/80, Avg Loss: 0.0004, LR: 0.015625\n",
      "Precision: 0.9027, Recall: 0.8729, F1 Score: 0.8844\n",
      "Evaluation Accuracy: 0.9723\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "best_model = train_model_glove(model, train_loader, dev_loader, dev_data, optimizer, criterion, word2idx, tag2idx, batch_size, output_file=\"./dev2.out\", epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9093, Recall: 0.8754, F1 Score: 0.8894\n",
      "Evaluation Accuracy: 0.9732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8893633722790155"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the state dictionary\n",
    "best_model = torch.load('./blstm2.pt')\n",
    "best_model.to(device)\n",
    "evaluate_glove(best_model, dev_loader, dev_data, word2idx, tag2idx, batch_size, \"./dev2.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51578 tokens with 5942 phrases; found: 5867 phrases; correct: 5151.\n",
      "accuracy:  97.76%; precision:  87.80%; recall:  86.69%; FB1:  87.24\n",
      "              LOC: precision:  95.40%; recall:  90.31%; FB1:  92.79  1739\n",
      "             MISC: precision:  81.38%; recall:  82.97%; FB1:  82.17  940\n",
      "              ORG: precision:  76.04%; recall:  86.88%; FB1:  81.10  1532\n",
      "              PER: precision:  94.32%; recall:  84.80%; FB1:  89.31  1656\n"
     ]
    }
   ],
   "source": [
    "# Evaluating METRICS with eval.py\n",
    "!python eval.py -p dev2.out -g data/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the state dictionary\n",
    "best_model = torch.load('./blstm2.pt')\n",
    "best_model.to(device)\n",
    "\n",
    "dataset_test = NERDataset_Glove_test(test_data['sentences'], word2idx)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, collate_fn=lambda batch: collate_fn_glove_test(batch, word2idx))\n",
    "evaluate_glove_test(best_model, test_loader, test_data, word2idx, tag2idx, batch_size, \"./test2.out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_matrix=None, embedding_dim=100, hidden_dim=256, linear_dim=128, lstm_layers=1, dropout=0.33, capitalization_dim=6, char_embedding_dim=25, char_cnn_kernel_size=3, char_cnn_output_dim=53):\n",
    "        super(BiLSTM_CNN, self).__init__()\n",
    "        \n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                torch.from_numpy(embedding_matrix).float(),\n",
    "                padding_idx=0,\n",
    "                freeze=False\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # Character-level CNN\n",
    "        self.char_embedding = nn.Embedding(num_embeddings=100, embedding_dim=char_embedding_dim, padding_idx=0)\n",
    "        self.char_cnn = nn.Conv1d(in_channels=char_embedding_dim, out_channels=char_cnn_output_dim, kernel_size=char_cnn_kernel_size, padding=1)\n",
    "        self.char_pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        # Capitalization embedding\n",
    "        self.capitalization_embedding = nn.Embedding(capitalization_dim, embedding_dim, padding_idx=0)  \n",
    "\n",
    "        # BiLSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim * 2 + char_cnn_output_dim,  # word + capitalization + character-level CNN output\n",
    "            hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout  \n",
    "        ).to(device)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, linear_dim).to(device)\n",
    "        self.elu = nn.ELU(alpha=0.01)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(linear_dim, tagset_size).to(device)\n",
    "    \n",
    "    def forward(self, x, capitalization_features, char_sequences):\n",
    "        # Word embeddings\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        # Character-level embeddings\n",
    "        char_embeds = self.char_embedding(char_sequences)  # (batch_size, seq_len, word_len, char_embedding_dim)\n",
    "        batch_size, seq_len, word_len, char_embed_dim = char_embeds.size()\n",
    "        char_embeds = char_embeds.view(batch_size * seq_len, word_len, char_embed_dim)  # (batch_size * seq_len, word_len, char_embedding_dim)\n",
    "        char_embeds = char_embeds.permute(0, 2, 1)  # (batch_size * seq_len, char_embedding_dim, word_len)\n",
    "        char_cnn_out = self.char_cnn(char_embeds)  # (batch_size * seq_len, char_cnn_output_dim, word_len)\n",
    "        char_pool_out = self.char_pool(char_cnn_out).squeeze(-1)  # (batch_size * seq_len, char_cnn_output_dim)\n",
    "        char_pool_out = char_pool_out.view(batch_size, seq_len, -1)  # (batch_size, seq_len, char_cnn_output_dim)\n",
    "        \n",
    "        # Capitalization embeddings\n",
    "        capitalization_embeds = self.capitalization_embedding(capitalization_features)  \n",
    "        \n",
    "        # Concatenate word, capitalization, and character-level embeddings\n",
    "        combined_embeds = torch.cat((embedded, capitalization_embeds, char_pool_out), dim=-1)  \n",
    "        \n",
    "        # BiLSTM\n",
    "        lstm_out, _ = self.lstm(combined_embeds)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        fc_out = self.fc(lstm_out)\n",
    "        elu_out = self.elu(fc_out)\n",
    "        drop_out = self.dropout(elu_out)\n",
    "        scores = self.classifier(drop_out)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset_CNN(Dataset):\n",
    "    def __init__(self, sentences, labels, word2idx, tag2idx, char2idx, max_word_len=20):\n",
    "        self.sentences = [[word2idx.get(word, 1) for word in sent] for sent in sentences]\n",
    "        self.capitalization_features = [[capitalization_to_index(get_capitalization_feature(word)) for word in sent] for sent in sentences]\n",
    "        self.labels = [[tag2idx.get(tag, -1) for tag in label] for label in labels]\n",
    "        \n",
    "        # Pad character sequences to a fixed length (max_word_len)\n",
    "        self.char_sequences = []\n",
    "        for sent in sentences:\n",
    "            char_seq_sent = []\n",
    "            for word in sent:\n",
    "                char_seq_word = [char2idx.get(char, 1) for char in word][:max_word_len]  \n",
    "                char_seq_word += [char2idx[\"<PAD>\"]] * (max_word_len - len(char_seq_word))\n",
    "                char_seq_sent.append(char_seq_word)\n",
    "            self.char_sequences.append(char_seq_sent)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.sentences[idx], dtype=torch.long),\n",
    "            torch.tensor(self.capitalization_features[idx], dtype=torch.long),\n",
    "            torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "            torch.tensor(self.char_sequences[idx], dtype=torch.long) \n",
    "        )\n",
    "\n",
    "class NERDataset_CNN_test(Dataset):\n",
    "    def __init__(self, sentences, word2idx, char2idx, max_word_len=20):\n",
    "        self.sentences = [[word2idx.get(word, 1) for word in sent] for sent in sentences]\n",
    "        self.capitalization_features = [[capitalization_to_index(get_capitalization_feature(word)) for word in sent] for sent in sentences]\n",
    "        \n",
    "        # Pad character sequences to a fixed length (max_word_len)\n",
    "        self.char_sequences = []\n",
    "        for sent in sentences:\n",
    "            char_seq_sent = []\n",
    "            for word in sent:\n",
    "                char_seq_word = [char2idx.get(char, 1) for char in word][:max_word_len]  \n",
    "                char_seq_word += [char2idx[\"<PAD>\"]] * (max_word_len - len(char_seq_word))  \n",
    "                char_seq_sent.append(char_seq_word)\n",
    "            self.char_sequences.append(char_seq_sent)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.sentences[idx], dtype=torch.long),\n",
    "            torch.tensor(self.capitalization_features[idx], dtype=torch.long),\n",
    "            torch.tensor(self.char_sequences[idx], dtype=torch.long) \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_cnn(batch, word_to_index, tag_to_index, char_to_index, pad_token='<PAD>', init_token='<S>', eos_token='</S>'):\n",
    "    sentences, cps, labels, char_sequences = zip(*batch)\n",
    "    \n",
    "    # Add <s> and </s> tokens for both sentences and labels\n",
    "    sentences_padded = [([word_to_index[init_token]] + list(sentence) + [word_to_index[eos_token]]) for sentence in sentences]\n",
    "    labels_padded = [([tag_to_index[pad_token]] + list(label) + [tag_to_index[pad_token]]) for label in labels]\n",
    "    cp_padded = [([capitalization_to_index(pad_token)] + list(cp) + [capitalization_to_index(pad_token)]) for cp in cps]\n",
    "    \n",
    "    # Pad the sentences to the length of the longest sentence in the batch\n",
    "    max_len = max(len(sentence) for sentence in sentences_padded)\n",
    "    sentences_padded = [sentence + [word_to_index[pad_token]] * (max_len - len(sentence)) for sentence in sentences_padded]\n",
    "    labels_padded = [label + [tag_to_index[pad_token]] * (max_len - len(label)) for label in labels_padded]\n",
    "    cp_padded = [cp + [capitalization_to_index(pad_token)] * (max_len - len(cp)) for cp in cp_padded]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    sentences_padded = torch.tensor(sentences_padded, dtype=torch.long).to(device)\n",
    "    labels_padded = torch.tensor(labels_padded, dtype=torch.long).to(device)\n",
    "    cp_padded = torch.tensor(cp_padded, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Pad character sequences to match the padded sentences\n",
    "    max_word_len = char_sequences[0].size(1)  # Length of the first word's character sequence\n",
    "    char_sequences_padded = []\n",
    "    for char_seq_sent in char_sequences:\n",
    "        # Move char_seq_sent to the same device as padding\n",
    "        char_seq_sent = char_seq_sent.to(device)\n",
    "        # Calculate padding needed\n",
    "        padding_length = max_len - char_seq_sent.size(0)\n",
    "        if padding_length > 0:\n",
    "            # Create padding tensor\n",
    "            padding = torch.full((padding_length, max_word_len), char_to_index[pad_token], dtype=torch.long).to(device)\n",
    "            # Concatenate padding to the character sequences\n",
    "            char_seq_sent_padded = torch.cat([char_seq_sent, padding], dim=0)\n",
    "        else:\n",
    "            char_seq_sent_padded = char_seq_sent\n",
    "        char_sequences_padded.append(char_seq_sent_padded)\n",
    "    \n",
    "    # Stack all character sequences into a single tensor\n",
    "    char_sequences_padded = torch.stack(char_sequences_padded).to(device)\n",
    "\n",
    "    return sentences_padded, labels_padded, cp_padded, char_sequences_padded\n",
    "\n",
    "def collate_fn_cnn_test(batch, word_to_index, char_to_index, pad_token='<PAD>', init_token='<S>', eos_token='</S>'):\n",
    "    sentences, cps, char_sequences = zip(*batch)\n",
    "    \n",
    "    # Add <s> and </s> tokens for both sentences and labels\n",
    "    sentences_padded = [([word_to_index[init_token]] + list(sentence) + [word_to_index[eos_token]]) for sentence in sentences]\n",
    "    cp_padded = [([capitalization_to_index(pad_token)] + list(cp) + [capitalization_to_index(pad_token)]) for cp in cps]\n",
    "    \n",
    "    # Pad the sentences to the length of the longest sentence in the batch\n",
    "    max_len = max(len(sentence) for sentence in sentences_padded)\n",
    "    sentences_padded = [sentence + [word_to_index[pad_token]] * (max_len - len(sentence)) for sentence in sentences_padded]\n",
    "    cp_padded = [cp + [capitalization_to_index(pad_token)] * (max_len - len(cp)) for cp in cp_padded]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    sentences_padded = torch.tensor(sentences_padded, dtype=torch.long).to(device)\n",
    "    cp_padded = torch.tensor(cp_padded, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Pad character sequences to match the padded sentences\n",
    "    max_word_len = char_sequences[0].size(1)  # Length of the first word's character sequence\n",
    "    char_sequences_padded = []\n",
    "    for char_seq_sent in char_sequences:\n",
    "        # Move char_seq_sent to the same device as padding\n",
    "        char_seq_sent = char_seq_sent.to(device)\n",
    "        # Calculate padding needed\n",
    "        padding_length = max_len - char_seq_sent.size(0)\n",
    "        if padding_length > 0:\n",
    "            # Create padding tensor\n",
    "            padding = torch.full((padding_length, max_word_len), char_to_index[pad_token], dtype=torch.long).to(device)\n",
    "            # Concatenate padding to the character sequences\n",
    "            char_seq_sent_padded = torch.cat([char_seq_sent, padding], dim=0)\n",
    "        else:\n",
    "            char_seq_sent_padded = char_seq_sent\n",
    "        char_sequences_padded.append(char_seq_sent_padded)\n",
    "    \n",
    "    # Stack all character sequences into a single tensor\n",
    "    char_sequences_padded = torch.stack(char_sequences_padded).to(device)\n",
    "\n",
    "    return sentences_padded, cp_padded, char_sequences_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_cnn(model, train_loader, dev_loader, data, optimizer, criterion, word2idx, tag2idx, char2idx, batch_size, output_file=\"./dev2.out\", epochs=10, accum_steps=1):\n",
    "    model.train()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=4)\n",
    "    model.to(device)\n",
    "    best_f1 = float(\"-inf\")\n",
    "    best_model = None\n",
    "    counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "\n",
    "        for step, (sentences, labels, cps, char_sequences) in enumerate(progress_bar):\n",
    "            sentences, cps, labels, char_sequences = sentences.to(device), cps.to(device), labels.to(device), char_sequences.to(device)\n",
    "            output = model(sentences, cps, char_sequences)\n",
    "\n",
    "            loss = criterion(output.view(-1, output.shape[-1]), labels.view(-1)) / accum_steps\n",
    "            loss.backward()\n",
    "\n",
    "            if (step + 1) % accum_steps == 0 or (step + 1) == len(train_loader):\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item() * accum_steps\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Avg Loss: {avg_loss:.4f}, LR: {scheduler.get_last_lr()[0]}\")\n",
    "        f1 = evaluate_cnn(model, dev_loader, data, word2idx, tag2idx, batch_size, output_file)  \n",
    "        scheduler.step(f1)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            torch.save(model, \"blstm_bonus.pt\")\n",
    "            best_model = model\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        if counter >= 10:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cnn(model, dataloader, data, word2idx, tag2idx, batch_size, output_file):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    true_lbls = []\n",
    "    preds_lst = []\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (sents, lbls, cps, char_sequences) in enumerate(dataloader):\n",
    "                sents = sents.to(device)\n",
    "                cps = cps.to(device)\n",
    "                char_sequences = char_sequences.to(device)\n",
    "                output = model(sents, cps, char_sequences)\n",
    "                preds = torch.argmax(output, dim=-1)\n",
    "                \n",
    "                for sent_idx, (sent, lbl, pred) in enumerate(zip(sents, lbls, preds)):\n",
    "                    for w_idx, (w_id, pred_id, _) in enumerate(zip(sent, pred, lbl)):\n",
    "                        w = idx2word.get(w_id.item(), \"<UNK>\")\n",
    "                        pred_tag = idx2tag[pred_id.item()]\n",
    "                        if w != \"<PAD>\" and w != \"<S>\" and w != \"</S>\":\n",
    "                            og_w = data[\"sentences\"][batch_idx * batch_size + sent_idx][w_idx-1]\n",
    "                            f.write(f\"{w_idx} {og_w} {pred_tag}\\n\")\n",
    "                    f.write(\"\\n\")\n",
    "                \n",
    "                for true, pred in zip(lbl, pred):\n",
    "                    if true.item() != -1:\n",
    "                        true_lbls.append(true.item())\n",
    "                        preds_lst.append(pred.item())\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_lbls, preds_lst, average='macro', zero_division=0)\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    correct = (torch.tensor(preds_lst) == torch.tensor(true_lbls)).sum().item()\n",
    "    total = len(true_lbls)\n",
    "    print(total)\n",
    "    print(f\"Evaluation Accuracy: {correct / total:.4f}\")\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cnn_test(model, dataloader, data, word2idx, tag2idx, batch_size, output_file):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (sents, cps, char_sequences) in enumerate(dataloader):\n",
    "                sents = sents.to(device)\n",
    "                cps = cps.to(device)\n",
    "                char_sequences = char_sequences.to(device)\n",
    "                output = model(sents, cps, char_sequences)\n",
    "                preds = torch.argmax(output, dim=-1)\n",
    "                \n",
    "                for sent_idx, (sent, pred) in enumerate(zip(sents, preds)):\n",
    "                    for w_idx, (w_id, pred_id) in enumerate(zip(sent, pred)):\n",
    "                        w = idx2word.get(w_id.item(), \"<UNK>\")\n",
    "                        pred_tag = idx2tag[pred_id.item()]\n",
    "                        if w != \"<PAD>\" and w != \"<S>\" and w != \"</S>\":\n",
    "                            og_w = data[\"sentences\"][batch_idx * batch_size + sent_idx][w_idx-1]\n",
    "                            f.write(f\"{w_idx} {og_w} {pred_tag}\\n\")\n",
    "                    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Function is used to create the embedding matrix from the glove embedding.\n",
    "def create_embedding_matrix(vocab, embeddings, embedding_dim=100):\n",
    "    # Here we are intializing a zero matrix of the correct dimensions.\n",
    "    embedding_matrix = np.zeros((len(vocab), embedding_dim))\n",
    "    # Here we are updating the initalized matrix with embedding vectors.\n",
    "    for word, idx in vocab.items():\n",
    "        if word in embeddings:\n",
    "            embedding_matrix[idx] = embeddings[word]\n",
    "        elif word.lower() in embeddings:\n",
    "            embedding_matrix[idx] = embeddings[word.lower()]\n",
    "        elif word.upper() in embeddings:\n",
    "            embedding_matrix[idx] = embeddings[word.upper()] \n",
    "        else:\n",
    "            # Initialize randomly with small values for OOV words\n",
    "            embedding_matrix[idx] = np.random.uniform(-0.25, 0.25, embedding_dim)\n",
    "    \n",
    "    return embedding_matrix\n",
    "\n",
    "# This Function is to to load GloVe embeddings\n",
    "def load_glove_embeddings(glove_file_path):\n",
    "    embeddings = {}\n",
    "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this function we are determining the capitalization feature label for each word.\n",
    "def get_capitalization_feature(word):\n",
    "    # Check if the word is fully uppercase\n",
    "    if word.isupper():\n",
    "        return 'allCaps'\n",
    "    # Check if the word starts with an uppercase letter and the rest are lowercase\n",
    "    elif word[0].isupper() and word[1:].islower():\n",
    "        return 'upperInitial'\n",
    "    # Check if the word is entirely lowercase\n",
    "    elif word.islower():\n",
    "        return 'lowercase'\n",
    "    # Check if the word has mixed capitalization\n",
    "    elif any(c.isupper() for c in word[1:]) and any(c.islower() for c in word[1:]):\n",
    "        return 'mixedCaps'\n",
    "    else:\n",
    "        return 'noinfo'\n",
    "\n",
    "# Here we are mapping each of the capitalization feature label to numeric label.\n",
    "def capitalization_to_index(capitalization):\n",
    "    lookup = {\n",
    "        '<PAD>' : 0,\n",
    "        'allCaps': 1,\n",
    "        'upperInitial': 2,\n",
    "        'lowercase': 3,\n",
    "        'mixedCaps': 4,\n",
    "        'noinfo': 5\n",
    "    }\n",
    "    return lookup.get(capitalization, 4)  # default to 'noinfo' if invalid\n",
    "\n",
    "# In this function we are checking for capitalization\n",
    "def adjust_case(word):\n",
    "    if word.islower():\n",
    "        return word.lower()\n",
    "    elif word.isupper():\n",
    "        return word.upper()\n",
    "    elif word.istitle():\n",
    "        return word.title()\n",
    "    else:\n",
    "        return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "linear_dim = 128\n",
    "dropout = 0.33\n",
    "batch_size = 16\n",
    "learning_rate = 0.25\n",
    "epochs = 80\n",
    "\n",
    "# Build Vocabulary from Training Data\n",
    "word2idx = {word: idx for idx, word in enumerate(set(word for sent in train_data['sentences'] for word in sent), start=4)}\n",
    "word2idx[\"<PAD>\"] = 0\n",
    "word2idx[\"<UNK>\"] = 1\n",
    "word2idx[\"<S>\"] = 2\n",
    "word2idx[\"</S>\"] = 3\n",
    "\n",
    "# Build Character Vocabulary\n",
    "char2idx = {char: idx for idx, char in enumerate(set(char for sent in train_data['sentences'] for word in sent for char in word), start=2)}\n",
    "char2idx[\"<PAD>\"] = 0\n",
    "char2idx[\"<UNK>\"] = 1\n",
    "\n",
    "tag2idx = {tag: idx for idx, tag in enumerate(set(tag for label in train_data['labels'] for tag in label))}\n",
    "tag2idx[\"<PAD>\"] = -1\n",
    "vocab_size = len(word2idx)\n",
    "tagset_size = len(tag2idx)-1\n",
    "\n",
    "glove_embeddings = load_glove_embeddings(\"./glove.6B.100d/glove.6B.100d.txt\")\n",
    "\n",
    "# Create the embedding matrix from the trained Word2Vec model\n",
    "embedding_matrix = create_embedding_matrix(word2idx, glove_embeddings, embedding_dim)\n",
    "\n",
    "# Model, Optimizer, and Loss Function\n",
    "model = BiLSTM_CNN(vocab_size, tagset_size, embedding_matrix, embedding_dim, hidden_dim, linear_dim, dropout=dropout).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-5, nesterov=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1).to(device)\n",
    "\n",
    "# Load Data\n",
    "dataset_train = NERDataset_CNN(train_data['sentences'], train_data['labels'], word2idx, tag2idx, char2idx)\n",
    "dataset_dev = NERDataset_CNN(dev_data['sentences'], dev_data['labels'], word2idx, tag2idx, char2idx)\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, collate_fn=lambda batch: collate_fn_cnn(batch, word2idx, tag2idx, char2idx))\n",
    "dev_loader = DataLoader(dataset_dev, batch_size=batch_size, collate_fn=lambda batch: collate_fn_cnn(batch, word2idx, tag2idx, char2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80, Avg Loss: 0.2547, LR: 0.25\n",
      "Precision: 0.7582, Recall: 0.6976, F1 Score: 0.7091\n",
      "3324\n",
      "Evaluation Accuracy: 0.9443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/80, Avg Loss: 0.1185, LR: 0.25\n",
      "Precision: 0.8100, Recall: 0.7597, F1 Score: 0.7736\n",
      "3324\n",
      "Evaluation Accuracy: 0.9537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/80, Avg Loss: 0.0775, LR: 0.25\n",
      "Precision: 0.8386, Recall: 0.8054, F1 Score: 0.8187\n",
      "3324\n",
      "Evaluation Accuracy: 0.9612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/80, Avg Loss: 0.0548, LR: 0.25\n",
      "Precision: 0.8540, Recall: 0.8171, F1 Score: 0.8314\n",
      "3324\n",
      "Evaluation Accuracy: 0.9633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/80, Avg Loss: 0.0394, LR: 0.25\n",
      "Precision: 0.8621, Recall: 0.8240, F1 Score: 0.8399\n",
      "3324\n",
      "Evaluation Accuracy: 0.9645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/80, Avg Loss: 0.0274, LR: 0.25\n",
      "Precision: 0.8529, Recall: 0.8347, F1 Score: 0.8404\n",
      "3324\n",
      "Evaluation Accuracy: 0.9657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/80, Avg Loss: 0.0214, LR: 0.25\n",
      "Precision: 0.8581, Recall: 0.8618, F1 Score: 0.8564\n",
      "3324\n",
      "Evaluation Accuracy: 0.9669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/80, Avg Loss: 0.0162, LR: 0.25\n",
      "Precision: 0.8759, Recall: 0.8675, F1 Score: 0.8684\n",
      "3324\n",
      "Evaluation Accuracy: 0.9693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/80, Avg Loss: 0.0126, LR: 0.25\n",
      "Precision: 0.8744, Recall: 0.8709, F1 Score: 0.8683\n",
      "3324\n",
      "Evaluation Accuracy: 0.9708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/80, Avg Loss: 0.0098, LR: 0.25\n",
      "Precision: 0.8702, Recall: 0.8545, F1 Score: 0.8586\n",
      "3324\n",
      "Evaluation Accuracy: 0.9675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/80, Avg Loss: 0.0088, LR: 0.25\n",
      "Precision: 0.8775, Recall: 0.8529, F1 Score: 0.8625\n",
      "3324\n",
      "Evaluation Accuracy: 0.9684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/80, Avg Loss: 0.0071, LR: 0.25\n",
      "Precision: 0.8873, Recall: 0.8669, F1 Score: 0.8741\n",
      "3324\n",
      "Evaluation Accuracy: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/80, Avg Loss: 0.0058, LR: 0.25\n",
      "Precision: 0.8880, Recall: 0.8483, F1 Score: 0.8660\n",
      "3324\n",
      "Evaluation Accuracy: 0.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/80, Avg Loss: 0.0061, LR: 0.25\n",
      "Precision: 0.8845, Recall: 0.8655, F1 Score: 0.8709\n",
      "3324\n",
      "Evaluation Accuracy: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/80, Avg Loss: 0.0050, LR: 0.25\n",
      "Precision: 0.8755, Recall: 0.8737, F1 Score: 0.8715\n",
      "3324\n",
      "Evaluation Accuracy: 0.9708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/80, Avg Loss: 0.0043, LR: 0.25\n",
      "Precision: 0.8885, Recall: 0.8816, F1 Score: 0.8828\n",
      "3324\n",
      "Evaluation Accuracy: 0.9723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/80, Avg Loss: 0.0041, LR: 0.25\n",
      "Precision: 0.8884, Recall: 0.8759, F1 Score: 0.8797\n",
      "3324\n",
      "Evaluation Accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/80, Avg Loss: 0.0039, LR: 0.25\n",
      "Precision: 0.8903, Recall: 0.8728, F1 Score: 0.8789\n",
      "3324\n",
      "Evaluation Accuracy: 0.9723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/80, Avg Loss: 0.0028, LR: 0.25\n",
      "Precision: 0.9036, Recall: 0.8935, F1 Score: 0.8965\n",
      "3324\n",
      "Evaluation Accuracy: 0.9765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/80, Avg Loss: 0.0019, LR: 0.25\n",
      "Precision: 0.9027, Recall: 0.8848, F1 Score: 0.8929\n",
      "3324\n",
      "Evaluation Accuracy: 0.9756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/80, Avg Loss: 0.0018, LR: 0.25\n",
      "Precision: 0.8823, Recall: 0.8786, F1 Score: 0.8789\n",
      "3324\n",
      "Evaluation Accuracy: 0.9741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/80, Avg Loss: 0.0018, LR: 0.25\n",
      "Precision: 0.8915, Recall: 0.8806, F1 Score: 0.8843\n",
      "3324\n",
      "Evaluation Accuracy: 0.9741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/80, Avg Loss: 0.0024, LR: 0.25\n",
      "Precision: 0.8658, Recall: 0.8744, F1 Score: 0.8668\n",
      "3324\n",
      "Evaluation Accuracy: 0.9702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/80, Avg Loss: 0.0028, LR: 0.25\n",
      "Precision: 0.8958, Recall: 0.8729, F1 Score: 0.8827\n",
      "3324\n",
      "Evaluation Accuracy: 0.9738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/80, Avg Loss: 0.0017, LR: 0.125\n",
      "Precision: 0.8900, Recall: 0.8747, F1 Score: 0.8807\n",
      "3324\n",
      "Evaluation Accuracy: 0.9732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/80, Avg Loss: 0.0009, LR: 0.125\n",
      "Precision: 0.8929, Recall: 0.8724, F1 Score: 0.8811\n",
      "3324\n",
      "Evaluation Accuracy: 0.9741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/80, Avg Loss: 0.0008, LR: 0.125\n",
      "Precision: 0.8924, Recall: 0.8799, F1 Score: 0.8847\n",
      "3324\n",
      "Evaluation Accuracy: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/80, Avg Loss: 0.0008, LR: 0.125\n",
      "Precision: 0.8885, Recall: 0.8727, F1 Score: 0.8784\n",
      "3324\n",
      "Evaluation Accuracy: 0.9735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/80, Avg Loss: 0.0007, LR: 0.125\n",
      "Precision: 0.8891, Recall: 0.8804, F1 Score: 0.8831\n",
      "3324\n",
      "Evaluation Accuracy: 0.9741\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "best_model = train_model_cnn(model, train_loader, dev_loader, dev_data, optimizer, criterion, word2idx, tag2idx, char2idx, batch_size, output_file=\"./dev_bonus.out\", epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9036, Recall: 0.8935, F1 Score: 0.8965\n",
      "3324\n",
      "Evaluation Accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8965035703194965"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the state dictionary\n",
    "best_model = torch.load('./blstm_bonus.pt')\n",
    "best_model.to(device)\n",
    "\n",
    "# Test the Model\n",
    "evaluate_cnn(best_model, dev_loader, dev_data, word2idx, tag2idx, batch_size, \"./dev_bonus.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51578 tokens with 5942 phrases; found: 6084 phrases; correct: 5259.\n",
      "accuracy:  97.92%; precision:  86.44%; recall:  88.51%; FB1:  87.46\n",
      "              LOC: precision:  94.00%; recall:  92.92%; FB1:  93.46  1816\n",
      "             MISC: precision:  77.57%; recall:  83.62%; FB1:  80.48  994\n",
      "              ORG: precision:  75.65%; recall:  86.65%; FB1:  80.78  1536\n",
      "              PER: precision:  93.15%; recall:  87.89%; FB1:  90.45  1738\n"
     ]
    }
   ],
   "source": [
    "# Evaluating METRICS with eval.py\n",
    "!python eval.py -p dev_bonus.out -g data/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state dictionary\n",
    "best_model = torch.load('./blstm_bonus.pt')\n",
    "best_model.to(device)\n",
    "\n",
    "# Test the Model\n",
    "dataset_test = NERDataset_CNN_test(test_data['sentences'], word2idx, char2idx)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, collate_fn=lambda batch: collate_fn_cnn_test(batch, word2idx, char2idx))\n",
    "evaluate_cnn_test(best_model, test_loader, test_data, word2idx, tag2idx, batch_size, \"./test_bonus.out\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
